{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Halo Analysis in yt-3.0"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In yt 3.0, operations relating to the analysis of halos (halo finding, merger tree creation, and individual halo analysis) are all brought together into a single framework. This framework is substantially different from the limited framework included in yt-2.x and is only backwards compatible in that output from old halo finders may be loaded.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from yt.mods import *\n",
      "from yt.analysis_modules.halo_analysis.api import HaloCatalog\n",
      "from yt.config import ytcfg\n",
      "path = ytcfg.get(\"yt\", \"test_data_dir\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Creating Halo Catalogs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A catalog of halos can be created from any initial dataset given to halo catalog through data_pf. These halos can be found using friends-of-friends, HOP, and Rockstar. The `finder_method` keyword dictates which halo finder to use. The available arguments are `'fof'`, `'hop'`, and` 'rockstar'`. For more details on the relative differences between these halo finders see"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "data_pf = load(path+'Enzo_64/RD0006/RedshiftOutput0006')\n",
      "\n",
      "hc = HaloCatalog(data_pf=data_pf, finder_method='hop')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A halo catalog may also be created from already run rockstar outputs. This method is not implemented for previously run friends-of-friends or HOP finders. Even though rockstar creates one file per processor, specifying any one file allows the full catalog to be loaded. Here we only specify the file output by the processor with ID 0. Note that the argument for supplying a rockstar output is `halos_pf`, not `data_pf`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "halo_pf = load(path+'rockstar_halos/out_0.0.bin')\n",
      "\n",
      "hc = HaloCatalog(halo_pf=halo_pf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Although supplying only the binary output of the rockstar halo finder is sufficient for creating a halo catalog, it is not possible to find any new information about the identified halos. To associate the halos with the dataset from which they were found, supply arguments to both `halos_pf` and `data_pf`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hc = HaloCatalog(data_pf=data_pf, halos_pf=halos_pf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A data container can also be supplied via keyword `data_source`, associated with either dataset, to control the spatial region in which halo analysis will be performed. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Analysis Using HaloCatalogs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Analysis is done by adding actions to the HaloCatalog. Each action is represented by a callback function that will be run on each halo. There are three types of actions:\n",
      "\n",
      "* Filters\n",
      "* Quantities\n",
      "* Callbacks\n",
      "\n",
      "All interaction with this analysis can be performed by importing from `halo_analysis`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from yt.analysis_modules.halo_analysis.api import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Filters"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A filter is a function that returns True or False. If the return value is True, any further queued analysis will proceed and the halo in question will be added to the final catalog. If the return value False, further analysis will not be performed and the halo will not be included in the final catalog."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hc.add_filter(\"quantity_value\" ,  \"matter_mass_200\" ,  \">\" ,  1E13 ,  \"Msun\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Currently `quantity_value` is the only available filter, but more can be added by the user by defining a function that accepts a `halo` object as the first argument and then adding it as an available filter. If you think that your filter may be of use to the general community, you can add it to `yt/analysis_modules/halo_analysis/halo_filters.py` and issue a pull request. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def my_filter_function(halo):\n",
      "    \n",
      "    # Define condition for filter\n",
      "    filter_value = True\n",
      "    \n",
      "    return filter_value\n",
      "\n",
      "add_filter(\"my_filter\", my_filter_function)\n",
      "\n",
      "hc.add_quantity(\"my_filter\", field_type=\"halos\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Quantities"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A quantity is a call back that returns a value or values. The return values are stored within the halo object in a dictionary called \u201cquantities.\u201d At the end of the analysis, all of these quantities will be written to disk as the final form of the generated \u201chalo catalog.\u201d"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the field value (\"halos\", \"particle_mass\") for this halo from the halo dataset\n",
      "hc.add_quantity(\"particle_mass\", field_type=\"halos\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Quantities may be available in the initial fields found in the halo catalog, or calculated from a function after supplying a definition. An example definition of center of mass is shown below. Currently available quantities are `center_of_mass` and `bulk_velocity`, and their definitions are available in `yt/analysis_modules/halo_analysis/halo_quantities.py` .  If you think that your quantity may be of use to the general community, add it to `halo_quantities.py` and issue a pull request."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def my_quantity_function(halo):\n",
      "    # Define quantity to return\n",
      "    quantity = 5\n",
      "    \n",
      "    return quantity\n",
      "\n",
      "add_quantity('my_quantity', my_quantity_function)\n",
      "\n",
      "hc.add_quantity(\"my_quantity\", field_type=\"halos\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Callbacks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A callback is actually the super class for quantities and filters and is a general purpose function that does something, anything, to a Halo object. This can include hanging new attributes off the Halo object, performing analysis and writing to disk, etc. A callback does not return anything. \n",
      "\n",
      "In the example below, we create a sphere for a halo with a radius that is twice the saved \u201cvirial_radius\u201d (in the quantities dict), recenter it on the location of maximum density, then do some profiling, compute virial quantities based on those profiles (storing them in the quantities dict), and then write the profiles to disk."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hc.add_callback(\"sphere\", radius_field=\"virial_radius\", factor=2.0)\n",
      "hc.add_callback(\"sphere_field_max_recenter\", (\"gas\", \"density\"))\n",
      "hc.add_callback(\"profile\", \"radius\", [(\"gas\", \"matter_mass\"),\n",
      "                                      (\"index\", \"cell_volume\")],\n",
      "                weight_field=None, accumulation=True,\n",
      "                output_dir=\"profiles\", storage=\"profiles\")\n",
      "hc.add_callback(\"virial_quantities\", [\"radius\", (\"gas\", \"matter_mass\")])\n",
      "hc.add_callback(\"save_profiles\", storage=\"profiles\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Currently available callbacks are located in `yt/analysis_modules/halo_analysis/halo_callbacks.py`. New callbacks may be added by using the syntax shown below.  If you think that your callback may be of use to the general community, add it to `halo_callbacks.py` and issue a pull request."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def my_callback_function(halo):\n",
      "    # Perform some callback actions here\n",
      "    x = 2\n",
      "    halo.x_val = x\n",
      "\n",
      "add_callback('my_callback', my_callback_function)\n",
      "\n",
      "hc.add_callback(\"my_callback\", field_type=\"halos\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Running Analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After all callbacks, quantities, and filters have been added, the analysis begins with a call to `HaloCatalog.create`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hc.create(save_halos=False, njobs=-1, dynamic=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `save_halos` keyword determines whether the actual Halo objects are saved after analysis on them has completed or whether just the contents of their quantities dicts will be retained for creating the final catalog. The looping over halos uses a call to `parallel_objects` allowing the user to control how many processors work on each halo. The final catalog is written to disk int the output directory given when the `HaloCatalog` object was created.\n",
      "\n",
      "All callbacks, quantities, and filters are stored in an \u201cactions\u201d list, meaning that they are executed in the same order in which they were added. This enables the use of simple, reusable, single action callbacks that depend on each other. This also prevents unecessary computation by allowing the user to add filters at multiple stages to skip remaining analysis if it is not warranted."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Saving, and Reloading HaloCatalogs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A `HaloCatalog` saved to disk can be reloaded as yt dataset with the standard call to `load`. Any side data, such as profiles, can be reloaded with a `load_profiles` callback and a call to `HaloCatalog.load`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hpf = load(path+\"halo_catalogs/catalog_0046/catalog_0046.0.h5\")\n",
      "hc = HaloCatalog(halos_pf=hpf,\n",
      "                 output_dir=\"halo_catalogs/catalog_0046\")\n",
      "hc.add_callback(\"load_profiles\", output_dir=\"profiles\",\n",
      "                filename=\"virial_profiles\")\n",
      "hc.load()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Full Example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we put everything together to perform some realistic analysis. First we load a dataset we have already found rockstar halos for."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load the data set with the full simulation information\n",
      "data_pf = load(path+'RD0027/RedshiftOutput0027')\n",
      "\n",
      "# Load the rockstar data files\n",
      "halos_pf = load(path+'RD0027/RedshiftOutput0027')\n",
      "\n",
      "# Instantiate a catalog using those two paramter files\n",
      "hc = HaloCatalog(data_pf=data_pf, halos_pf=halos_pf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First we add a filter to only look at the most massive halos; those with masses great than $10^{13}~M_\\odot$. Note that all following analysis will only be performed on these massive halos and we will not waste computational time calculating quantities for halos we are not interested in. We then define a series of analysis actions for the halos that have passed the filter."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Filter out less massive halos\n",
      "hc.add_filter(\"quantity_value\", \"particle_mass\", \">\", 1e13, \"Msun\")\n",
      "\n",
      "# attach a sphere object to each halo whose radius extends to twice the radius of the halo\n",
      "hc.add_callback(\"sphere\", factor=2.0)\n",
      "\n",
      "# Define a virial radius for the halo.\n",
      "# As this is a callback, not a quantity the virial radius will not be written\n",
      "#    out with the rest of the halo properties in the final halo catalog.\n",
      "hc.add_callback(\"virial_quantities\", [\"radius\"])\n",
      "\n",
      "# use the sphere to calculate radial profiles of gas density weighted by cell volume in terms of the virial radius\n",
      "hc.add_callback(\"profile\", \"virial_radius\", [(\"gas\", \"density\")],\n",
      "                weight_field=\"cell_volume\", accumulation=False,\n",
      "                storage=\"virial_profiles\")\n",
      "\n",
      "# Save the profiles\n",
      "hc.add_callback(\"save_profiles\", storage=\"virial_profiles\", output_dir=\"profiles\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We then create the halo catalog. No analysis is done before this call to create. By adding callbacks and filters we are simply queuing up the actions we want to take. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "hc.create()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally we load these profiles back in and make a pretty plot. This step may be performed completely separately from the rest of the script. This allows you to create a single script that will be run first on a supercomputer to perform all of the dataset-requiring analysis and then later on a local machine to load the halo data into memory for further analysis and plotting."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}